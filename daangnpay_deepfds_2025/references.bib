@article{dhanorkar2019,
      author = {Dhanorkar, Suvrat},
      title = {Environmental Benefits of Internet-Enabled C2C Closed-Loop Supply Chains: A Quasi-Experimental Study of Craigslist},
      journal = {Management Science},
      volume = {65},
      number = {2},
      pages = {660--680},
      year = {2019},
      doi = {10.1287/mnsc.2017.2963},
      url = {https://doi.org/10.1287/mnsc.2017.2963}
}

@article{filho2024,
      author = {Moacir {Godinho Filho} and Gilberto {Miller Devós Ganga} and Fabiana Leticia Lizarelli and Claudia Lorena {Cárdenas Blaz} and Thais Moreira Tavares},
      title = {Circular Economy via Chat: Evaluation of Adoption and Use of {WhatsApp} Instant Messaging Platform for Trading Second-Hand Products},
      journal = {Journal of Cleaner Production},
      volume = {460},
      pages = {142510},
      year = {2024},
      issn = {0959-6526},
      doi = {10.1016/j.jclepro.2024.142510},
      url = {https://www.sciencedirect.com/science/article/pii/S0959652624019589}
}

@phdthesis{chen2024,
      author = {Chen, Zhuoli and Guo, Shunan and Mo, Zonglin},
      title = {How Second-Hand Trading Platforms Facilitate Online Fraud: A Case Study of China's Largest Second-Hand Marketplace},
      school = {The University of Hong Kong},
      year = {2024},
      url = {http://hdl.handle.net/10722/352837}
}

@techreport{gerdelius2024,
      author = {Gerdelius, Patrik and Sj{\"o}nneby, Hugo},
      title = {Detecting Fraudulent User Behaviour: A Study of User Behaviour and Machine Learning in Fraud Detection},
      institution = {Uppsala University, Analysis and Partial Differential Equations},
      number = {UPTEC STS 24003},
      year = {2024},
      pages = {41}
}

@misc{cahyawijaya2024,
      author = {Cahyawijaya, Samuel and Lovenia, Holy and Fung, Pascale},
      title = {{LLMs} Are Few-Shot In-Context Low-Resource Language Learners},
      year = {2024},
      eprint = {2403.16512},
      archivePrefix = {arXiv},
      primaryClass = {cs.CL},
      url = {https://arxiv.org/abs/2403.16512}
}

@inproceedings{wu2025why,
      author = {Wu, Shiguang and Wang, Yaqing and Yao, Quanming},
      title = {Why In-Context Learning Models are Good Few-Shot Learners?},
      booktitle = {The Thirteenth International Conference on Learning Representations},
      year = {2025},
      url = {https://openreview.net/forum?id=iLUcsecZJp}
}

@inproceedings{agarwal2024,
      author = {Agarwal, Rishabh and Singh, Avi and Zhang, Lei and Bohnet, Bernd and Rosias, Luis and Chan, Stephanie and Zhang, Biao and Anand, Ankesh and Abbas, Zaheer and Nova, Azade and Co-Reyes, John D. and Chu, Eric and Behbahani, Feryal and Faust, Aleksandra and Larochelle, Hugo},
      title = {Many-Shot In-Context Learning},
      booktitle = {Advances in Neural Information Processing Systems},
      volume = {37},
      year = {2024},
      pages = {76930--76966},
      publisher = {Curran Associates, Inc.}
}


@inproceedings{pan2020,
      author = {Pan, Yushan},
      title = {Cyber Trust in the Norwegian Online Flea Market: An Ethnographic Study on Fraud},
      booktitle = {HCI International 2020 - Posters},
      year = {2020},
      pages = {589--596},
      publisher = {Springer International Publishing},
      doi = {doi.org/10.1007/978-3-030-50732-9_76}
}

@inproceedings{huang2024ptp,
      author = {Huang, Wenxi and Zhao, Zhangyi and Chen, Xiaojun and Zhang, Qin and Li, Mark Junjie and Su, Hanjing and Wu, Qingyao},
      title = {A Payment Transaction Pre-training Model for Fraud Transaction Detection},
      year = {2024},
      isbn = {9798400704369},
      publisher = {Association for Computing Machinery},
      address = {New York, NY, USA},
      url = {https://doi.org/10.1145/3627673.3679670},
      doi = {10.1145/3627673.3679670},
      abstract = {The surge in merchant fraud poses a significant threat to market order and consumer security. Effective security monitoring for merchants is crucial in safeguarding the digital life ecosystem and users' financial well-being. Detecting daily fraudulent payment transactions, a challenging task for current methods, requires efficient transformation of transactions into embeddings, especially in representing merchants based on their behavioral transactions. To address this, we propose the Grouping Sampling-based Sequence Generation (GSSG) method to generate meaningful sequences, enabling interactions among correlated transactions. We introduce Hierarchical Embedding Learning (HEL) and Hierarchical Masking pre-training (HMP) for the effective representation of hierarchical structures within flat transaction sequences. Pretrained on WeChat Pay data, our model, PTP, demonstrates superior performance in downstream fraud transaction detection, especially in few-shot learning scenarios, showcasing great potential in payment transaction scenarios.},
      booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
      pages = {932–941},
      numpages = {10},
      keywords = {fraud detection, fraud merchant detection, fraud transaction detection, payment transaction, pre-training model},
      location = {Boise, ID, USA},
      series = {CIKM '24}
}

@article{lee2025,
      author = {Jean Lee and Nicholas Stevens and Soyeon Caren Han},
      title = {Large Language Models in Finance ({FinLLMs})},
      journal = {Neural Computing and Applications},
      year = {2025},
      doi = {10.1007/s00521-024-10495-6}
}


@article{huang2023,
      author = {Huang, Allen H. and Wang, Hui and Yang, Yi},
      title = {{FinBERT}: A Large Language Model for Extracting Information from Financial Text},
      journal = {Contemporary Accounting Research},
      volume = {40},
      number = {2},
      pages = {806--841},
      year = {2023},
      doi = {10.1111/1911-3846.12832}
}


@inproceedings{zhao2024fewshing,
      author={Zhao, Peng and Jin, Shuyuan},
      booktitle={2024 IEEE 4th International Conference on Software Engineering and Artificial Intelligence (SEAI)}, 
      title={Fewshing: A Few-Shot Learning Approach to Phishing Email Detection}, 
      year={2024},
      volume={},
      number={},
      pages={371-375},
      keywords={Training;Privacy;Analytical models;Accuracy;Phishing;Learning (artificial intelligence);Electronic mail;phishing emails detection;few-shot learning;contrastive learning},
      doi={10.1109/SEAI62072.2024.10674290}
}

@misc{chen2024longcontext,
      title={Long Context is Not Long at All: A Prospector of Long-Dependency Data for Large Language Models}, 
      author={Longze Chen and Ziqiang Liu and Wanwei He and Yunshui Li and Run Luo and Min Yang},
      year={2024},
      eprint={2405.17915},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.17915}, 
}

@misc{bertsch2025,
      title={In-Context Learning with Long-Context Models: An In-Depth Exploration}, 
      author={Amanda Bertsch and Maor Ivgi and Emily Xiao and Uri Alon and Jonathan Berant and Matthew R. Gormley and Graham Neubig},
      year={2025},
      eprint={2405.00200},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.00200}, 
}

@inproceedings{khanum2024,
      author = {Khanum, Arshiya and Chaitra, K S and Singh, Brijesh and Gomathi, C},
      title = {Fraud Detection in Financial Transactions: A Machine Learning Approach vs. Rule-Based Systems},
      booktitle = {2024 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)},
      year = {2024},
      pages = {1--5},
      doi = {10.1109/IITCEE59897.2024.10467759}
}


@inproceedings{raghavan2019,
      author = {Raghavan, Pradheepan and El Gayar, Neamat},
      title = {Fraud Detection using Machine Learning and Deep Learning},
      booktitle = {2019 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE)},
      year = {2019},
      pages = {334--339},
      doi = {10.1109/ICCIKE47802.2019.9004231}
}



@inproceedings{korkanti2024,
      author={Korkanti, Sukanth},
      title={Enhancing Financial Fraud Detection Using {LLMs} and Advanced Data Analytics},
      booktitle={2024 2nd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)},
      year={2024},
      pages={1328--1334},
      doi={10.1109/ICSSAS64001.2024.10760895}
}


@article{renjith2018,
      author={Renjith, Shini},
      title={Detection of Fraudulent Sellers in Online Marketplaces using Support Vector Machine Approach},
      journal={International Journal of Engineering Trends and Technology (IJETT)},
      volume={57},
      number={1},
      year={2018},
      month={March},
      pages={48--53},
      doi={10.14445/22315381/IJETT-V57P210}
}




@inproceedings{yu2024card_fds,
      author={Yu, Chang and Xu, Yongshun and Cao, Jin and Zhang, Ye and Jin, Yixin and Zhu, Mengran},
      title={Credit Card Fraud Detection Using Advanced Transformer Model},
      booktitle={2024 IEEE International Conference on Metaverse Computing, Networking, and Applications (MetaCom)},
      year={2024},
      pages={343--350},
      doi={10.1109/MetaCom62920.2024.00064}
}

@misc{chen2021pareto,
      author={Chen, Zhengyu and Ge, Jixie and Zhan, Heshen and Huang, Siteng and Wang, Donglin},
      title={Pareto Self-Supervised Training for Few-Shot Learning},
      year={2021},
      eprint={2104.07841},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2104.07841}
}

@misc{lyu2023attention,
      author={Lyu, Weimin and Zheng, Songzhu and Pang, Lu and Ling, Haibin and Chen, Chao},
      title={Attention-Enhancing Backdoor Attacks Against {BERT}-based Models},
      year={2023},
      eprint={2310.14480},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.14480}
}

@article{liu2019stockline,
      author={Liu, Xiaopeng and Liu, Yan and Zhang, Meng and Chen, Xianzhong and Li, Jiangyun},
      title={Improving Stockline Detection of Radar Sensor Array Systems in Blast Furnaces Using a Novel Encoder--Decoder Architecture},
      journal={Sensors},
      volume={19},
      number={16},
      year={2019},
      pages={3470},
      doi={10.3390/s19163470},
      url={https://www.mdpi.com/1424-8220/19/16/3470}
}

@inproceedings{pandey2024rag,
      author = {Pandey, Anubha},
      title = {Retrieval Augmented Fraud Detection},
      year = {2024},
      isbn = {9798400710810},
      publisher = {Association for Computing Machinery},
      address = {New York, NY, USA},
      url = {https://doi.org/10.1145/3677052.3698692},
      doi = {10.1145/3677052.3698692},
      abstract = {Fraud detection in the financial landscape poses unique multifaceted challenges, such as extreme class imbalance, high feature cardinality, adversarial dynamics, and non-IID data distributions. While traditional machine learning methods [1] and recent deep learning approaches [21, 22, 37] have made strides in tackling these issues, significant room for improvement remains. In this paper, we propose Retrieval Augmented Fraud Detection (RAFD), a novel approach that builds upon the success of self-supervised representation learning methods like SAINT [32] and incorporates principles from Retrieval Augmented Classification (RAC) [23] to enhance fraud detection capabilities. RAFD utilizes a pre-trained SAINT encoder augmented with retrieval, integration, and predictor modules, jointly trained to dynamically leverage similar instances for each input sample. This approach enables context-rich decision-making, adaptive sampling, and improved generalization, particularly for the underrepresented fraud class. By combining instance-based learning with deep classification techniques, RAFD offers a more robust and adaptable framework for tackling the core challenges of fraud detection. Experimental results demonstrate RAFD’s superior performance over existing methods, particularly in handling class imbalance and detecting nuanced fraud patterns present in the out-of-time test set. This research contributes a significant advancement in fraud detection methodology, with potential implications for enhancing financial security and maintaining the integrity of digital financial ecosystems.},
      booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
      pages = {328-335},
      numpages = {8},
      keywords = {Credit Card Fraud Detection, Imbalanced Classification, Retrieval Augmented Classification, Self-supervised Learning, Transformers},
      location = {Brooklyn, NY, USA},
      series = {ICAIF '24}
}

@inproceedings{lin2024graphtransformer,
      author = {Lin, Junhong and Guo, Xiaojie and Zhu, Yada and Mitchell, Samuel and Altman, Erik and Shun, Julian},
      title = {FraudGT: A Simple, Effective, and Efficient Graph Transformer for Financial Fraud Detection},
      year = {2024},
      isbn = {9798400710810},
      publisher = {Association for Computing Machinery},
      address = {New York, NY, USA},
      url = {https://doi.org/10.1145/3677052.3698648},
      doi = {10.1145/3677052.3698648},
      abstract = {Fraud detection plays a crucial role in the financial industry, preventing significant financial losses. Traditional rule-based systems and manual audits often struggle with the evolving nature of fraud schemes and the vast volume of transactions. Recent advances in machine learning, particularly graph neural networks (GNNs), have shown promise in addressing these challenges. However, GNNs still face limitations in learning intricate patterns, effectively utilizing edge attributes, and maintaining efficiency on large financial graphs. To address these limitations, we introduce FraudGT, a simple, effective, and efficient graph transformer (GT) model specifically designed for fraud detection in financial transaction graphs. FraudGT leverages edge-based message passing gates and an edge attribute-based attention bias to enhance its ability to discern important transactional features and differentiate between normal and fraudulent transactions. Our model achieves state-of-the-art performance in detecting fraudulent activities while demonstrating high throughput and significantly lower latency compared to existing methods. We validate the effectiveness of FraudGT through extensive experiments on multiple large-scale synthetic financial datasets. FraudGT consistently outperforms other models, achieving 7.8–17.8\% higher F1 scores, while delivering an average of 2.4 \texttimes{} greater throughput and reduced latency. Our code and datasets are available at https://github.com/junhongmit/FraudGT.},
      booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
      pages = {292-300},
      numpages = {9},
      keywords = {Financial transaction networks, fraud detection, graph learning, graph neural networks, graph transformers},
      location = {Brooklyn, NY, USA},
      series = {ICAIF '24}
}


@article{yoo2023medicare,
      author={Yoo, Yeeun and Shin, Jinho and Kyeong, Sunghyon},
      journal={IEEE Access}, 
      title={Medicare Fraud Detection Using Graph Analysis: A Comparative Study of Machine Learning and Graph Neural Networks}, 
      year={2023},
      volume={11},
      number={},
      pages={88278-88294},
      keywords={Graph neural networks;Medical services;Biological system modeling;Machine learning;Insurance;Medical diagnostic imaging;Fraud;Graph neural network;graph centrality measure;machine learning;medicare fraud detection},
      doi={10.1109/ACCESS.2023.3305962}
}




@inproceedings{hasan2022ecommerce,
      author={Hasan, Fahim and Mondal, Sourov Kumar and Kabir, Md. Rayhan and Al Mamun, Md Abdullah and Rahman, Nur Salman and Hossen, Md. Sagar},
      booktitle={2022 7th International Conference on Communication and Electronics Systems (ICCES)}, 
      title={E-commerce Merchant Fraud Detection using Machine Learning Approach}, 
      year={2022},
      volume={},
      number={},
      pages={1123-1127},
      keywords={},
      doi={10.1109/ICCES54183.2022.9835868}
}


@article{bhattacharya2024fraud,
      title = {Accounting fraud detection using contextual language learning},
      journal = {International Journal of Accounting Information Systems},
      volume = {53},
      pages = {100682},
      year = {2024},
      issn = {1467-0895},
      doi = {https://doi.org/10.1016/j.accinf.2024.100682},
      url = {https://www.sciencedirect.com/science/article/pii/S1467089524000150},
      author = {Indranil Bhattacharya and Ana Mickovic},
      keywords = {Accounting fraud detection, Natural Language Processing, BERT, Information Retrieval},
      abstract = {Accounting fraud is a widespread problem that causes significant damage in the economic market. Detection and investigation of fraudulent firms require a large amount of time, money, and effort for corporate monitors and regulators. In this study, we explore how textual contents from financial reports help in detecting accounting fraud. Pre-trained contextual language learning models, such as BERT, have significantly advanced natural language processing in recent years. We fine-tune the BERT model on Management Discussion and Analysis (MD&A) sections of annual 10-K reports from the Securities and Exchange Commission (SEC) database. Our final model outperforms the textual benchmark model and the quantitative benchmark model from the previous literature by 15% and 12%, respectively. Further, our model identifies five times more fraudulent firm-year observations than the textual benchmark by investigating the same number of firms, and three times more than the quantitative benchmark. Optimizing this investigation process, where more fraudulent observations are detected in the same size of the investigation sample, would be of great economic significance for regulators, investors, financial analysts, and auditors.}
}

@misc{brown2020llm_fewshot,
      author={Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
      title={Language Models are Few-Shot Learners},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.14165}
}

@misc{liu2024anomaly,
      author={Liu, Shuo and Yao, Di and Fang, Lanting and Li, Zhetao and Li, Wenbin and Feng, Kaiyu and Ji, XiaoWen and Bi, Jingping},
      title={{AnomalyLLM}: Few-shot Anomaly Edge Detection for Dynamic Graphs using Large Language Models},
      year={2024},
      eprint={2405.07626},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.07626}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
