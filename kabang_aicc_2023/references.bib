@misc{lialin2023scaling,
      title={Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning}, 
      author={Vladislav Lialin and Vijeta Deshpande and Anna Rumshisky},
      year={2023},
      eprint={2303.15647},
      archivePrefix={arXiv},
}

@misc{zhao2023survey,
      title={A Survey of Large Language Models}, 
      author={Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei Wang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie Zhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and Zhipeng Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu Tang and Zikang Liu and Peiyu Liu and Jian-Yun Nie and Ji-Rong Wen},
      year={2023},
      eprint={2303.18223},
      archivePrefix={arXiv},
}


@misc{brynjolfsson2023generative,
      title={Generative AI at Work}, 
      author={Erik Brynjolfsson and Danielle Li and Lindsey Raymond},
      year={2023},
      eprint={2304.11771},
      archivePrefix={arXiv},
}

@misc{peng2023check,
      title={Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback}, 
      author={Baolin Peng and Michel Galley and Pengcheng He and Hao Cheng and Yujia Xie and Yu Hu and Qiuyuan Huang and Lars Liden and Zhou Yu and Weizhu Chen and Jianfeng Gao},
      year={2023},
      eprint={2302.12813},
      archivePrefix={arXiv},
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}


@misc{eloundou2023gpts,
      title={GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models}, 
      author={Tyna Eloundou and Sam Manning and Pamela Mishkin and Daniel Rock},
      year={2023},
      eprint={2303.10130},
      archivePrefix={arXiv},
}

@book{polanyi:1966,
  title   = {The Tacit Dimension},
  author = {Michael Polanyi},
  year    = {1966},
  address = {Chicago, IL},
  publisher = {University of Chicago Press},
}

@inproceedings{Chen_Shuai_2021, 
    title={Meta-Transfer Learning for Low-Resource Abstractive Summarization}, 
    volume={35}, 
    url={https://ojs.aaai.org/index.php/AAAI/article/view/17503}, DOI={10.1609/aaai.v35i14.17503}, 
    number={14}, 
    journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
    author={Chen, Yi-Syuan and Shuai, Hong-Han}, 
    year={2021}, 
    month={May}, 
    pages={12692-12700} 
}


@inproceedings{brown2020gpt3,
      author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
      booktitle = {Advances in Neural Information Processing Systems},
      editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
      pages = {1877--1901},
      publisher = {Curran Associates, Inc.},
      title = {Language Models are Few-Shot Learners},
      volume = {33},
      year = {2020}
}

@misc{chowdhery2022palm,
      title={PaLM: Scaling Language Modeling with Pathways}, 
      author={Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Ben Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garcia and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathy Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
      year={2022},
      eprint={2204.02311},
      archivePrefix={arXiv},
}

@misc{zhang2022opt,
      title={OPT: Open Pre-trained Transformer Language Models}, 
      author={Susan Zhang and Stephen Roller and Naman Goyal and Mikel Artetxe and Moya Chen and Shuohui Chen and Christopher Dewan and Mona Diab and Xian Li and Xi Victoria Lin and Todor Mihaylov and Myle Ott and Sam Shleifer and Kurt Shuster and Daniel Simig and Punit Singh Koura and Anjali Sridhar and Tianlu Wang and Luke Zettlemoyer},
      year={2022},
      eprint={2205.01068},
      archivePrefix={arXiv},
}


@inproceedings{gliwa2019samsum,
    title = "{SAMS}um Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization",
    author = "Gliwa, Bogdan  and
      Mochol, Iwona  and
      Biesek, Maciej  and
      Wawer, Aleksander",
    booktitle = "Proceedings of the 2nd Workshop on New Frontiers in Summarization",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    pages = "70--79",
}

@misc{zhong2021qmsum,
      title={QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization}, 
      author={Ming Zhong and Da Yin and Tao Yu and Ahmad Zaidi and Mutethia Mutuma and Rahul Jha and Ahmed Hassan Awadallah and Asli Celikyilmaz and Yang Liu and Xipeng Qiu and Dragomir Radev},
      year={2021},
      eprint={2104.05938},
      archivePrefix={arXiv},
}

@misc{ouyang2022training,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
}

@misc{liu2023summary,
      title={Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models}, 
      author={Yiheng Liu and Tianle Han and Siyuan Ma and Jiayue Zhang and Yuanyuan Yang and Jiaming Tian and Hao He and Antong Li and Mengshen He and Zhengliang Liu and Zihao Wu and Dajiang Zhu and Xiang Li and Ning Qiang and Dingang Shen and Tianming Liu and Bao Ge},
      year={2023},
      eprint={2304.01852},
      archivePrefix={arXiv},
}

@article{syverson:2011,
    Author = {Syverson, Chad},
    Title = {What Determines Productivity?},
    Journal = {Journal of Economic Literature},
    Volume = {49},
    Number = {2},
    Year = {2011},
    Month = {Jun},
    Pages = {326-65},
}

@article{Prodan2022,
    author = {George Prodan and Elena Pelican},
    title = {Prompt scoring system for dialogue summarization using GPT-3},
    year = {2022},
    month = {5},
    journal = {TechRxiv},
}

@inproceedings{park-etal-2022-leveraging,
    title = "Leveraging Non-dialogue Summaries for Dialogue Summarization",
    author = "Park, Seongmin  and Shin, Dongchan  and Lee, Jihwa",
    booktitle = "Proceedings of the First Workshop On Transcript Understanding",
    month = Oct,
    year = "2022",
    address = "Gyeongju, South Korea",
    publisher = "International Conference on Computational Linguistics",
    pages = "1--7"
}

@inproceedings{maynez-etal-2020-faithfulness,
    title = "On Faithfulness and Factuality in Abstractive Summarization",
    author = "Maynez, Joshua  and
      Narayan, Shashi  and
      Bohnet, Bernd  and
      McDonald, Ryan",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "1906--1919",
}

@inproceedings{ladhak-etal-2022-faithful,
    title = "Faithful or Extractive? On Mitigating the Faithfulness-Abstractiveness Trade-off in Abstractive Summarization",
    author = "Ladhak, Faisal  and
      Durmus, Esin  and
      He, He  and
      Cardie, Claire  and
      McKeown, Kathleen",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    pages = "1410--1421",
}

@misc{peng2023instruction,
      title={Instruction Tuning with GPT-4}, 
      author={Baolin Peng and Chunyuan Li and Pengcheng He and Michel Galley and Jianfeng Gao},
      year={2023},
      eprint={2304.03277},
      archivePrefix={arXiv},
}

@misc{wang2023selfinstruct,
      title={Self-Instruct: Aligning Language Models with Self-Generated Instructions}, 
      author={Yizhong Wang and Yeganeh Kordi and Swaroop Mishra and Alisa Liu and Noah A. Smith and Daniel Khashabi and Hannaneh Hajishirzi},
      year={2023},
      eprint={2212.10560},
      archivePrefix={arXiv},
}

@inproceedings{lee2021optimizing,
    title = "Optimizing Domain Specificity of Transformer-based Language Models for Extractive Summarization of Financial News Articles in {K}orean",
    author = "Lee, Huije  and
      Yang, Wonsuk  and
      Park, Chaehun  and
      Song, Hoyun  and
      Jang, Eugene  and
      Park, Jong C.",
    booktitle = "Proceedings of the 35th Pacific Asia Conference on Language, Information and Computation",
    month = "11",
    year = "2021",
    address = "Shanghai, China",
    publisher = "Association for Computational Lingustics",
    pages = "611--621",
}

@misc{araci2019finbert,
      title={FinBERT: Financial Sentiment Analysis with Pre-trained Language Models}, 
      author={Dogu Araci},
      year={2019},
      eprint={1908.10063},
      archivePrefix={arXiv}
}

@misc{gudibande2023false,
      title={The False Promise of Imitating Proprietary LLMs}, 
      author={Arnav Gudibande and Eric Wallace and Charlie Snell and Xinyang Geng and Hao Liu and Pieter Abbeel and Sergey Levine and Dawn Song},
      year={2023},
      eprint={2305.15717},
      archivePrefix={arXiv},
}

@misc{huang2023,
      title={The Factual Inconsistency Problem in Abstractive Text Summarization: A Survey}, 
      author={Yichong Huang and Xiachong Feng and Xiaocheng Feng and Bing Qin},
      year={2023},
      eprint={2104.14839},
      archivePrefix={arXiv},
}

@inproceedings{lee2020rdass,
    title = "Reference and Document Aware Semantic Evaluation Methods for {K}orean Language Summarization",
    author = "Lee, Dongyub  and
      Shin, Myeong Cheol  and
      Whang, Taesun  and
      Cho, Seungwoo  and
      Ko, Byeongil  and
      Lee, Daniel  and
      Kim, EungGyun  and
      Jo, Jaechoon",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    pages = "5604--5616",
}

@inproceedings{lin2004rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    pages = "74--81",
}

@misc{ganesan2018rouge,
      title={ROUGE 2.0: Updated and Improved Measures for Evaluation of Summarization Tasks}, 
      author={Kavita Ganesan},
      year={2018},
      eprint={1803.01937},
      archivePrefix={arXiv},
}

@article{vanDerMaaten2008,
  added-at = {2015-06-19T12:07:15.000+0200},
  author = {van der Maaten, Laurens and Hinton, Geoffrey},
  interhash = {370ba8b9e1909b61880a6f47c93bcd49},
  intrahash = {8b9aebb404ad4a4c6a436ea413550b30},
  journal = {Journal of Machine Learning Research},
  keywords = {dimensionality_reduction tSNE visualization},
  pages = {2579--2605},
  timestamp = {2015-08-19T15:19:11.000+0200},
  title = {Visualizing Data using {t-SNE} },
  volume = 9,
  year = 2008
}



@misc{polyglot-ko:2022,
  title = {{Polyglot-Ko: Open-Source Korean Autoregressive Language Model}},
  author = {Ko, Hyunwoong and Yang, Kichang and Ryu, Minho and Choi, Taekyoon and Yang, Seungmu and Hyun, jiwung and Park, Sungho},
  month = {9},
  year = {2022},
}

@misc{polyglot-ko2023note,
      title={A Technical Report for Polyglot-Ko: Open-Source Large-Scale Korean Language Models}, 
      author={Hyunwoong Ko and Kichang Yang and Minho Ryu and Taekyoon Choi and Seungmu Yang and Jiwung Hyun and Sungho Park and Kyubyong Park},
      year={2023},
      eprint={2306.02254},
      archivePrefix={arXiv},
}

@misc{white2023prompt,
      title={A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT}, 
      author={Jules White and Quchen Fu and Sam Hays and Michael Sandborn and Carlos Olea and Henry Gilbert and Ashraf Elnashar and Jesse Spencer-Smith and Douglas C. Schmidt},
      year={2023},
      eprint={2302.11382},
      archivePrefix={arXiv},
}

@inproceedings{wei2022finetuned,
      title={Finetuned Language Models are Zero-Shot Learners},
      author={Jason Wei and Maarten Bosma and Vincent Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V Le},
      booktitle={International Conference on Learning Representations},
      year={2022},
      url={https://openreview.net/forum?id=gEZrGCozdqR}
}


@misc{li2023chatdoctor,
      title={ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge}, 
      author={Yunxiang Li and Zihan Li and Kai Zhang and Ruilong Dan and You Zhang},
      year={2023},
      eprint={2303.14070},
      archivePrefix={arXiv},
}

@article{ding2023,
    title = {Parameter-efficient fine-tuning of large-scale pre-trained language models},
    author = {Ding, Ning and Qin, Yujia and Yang, Guang
             and Wei, Fuchao and Yang, Zonghan
             and Su, Yusheng and Hu, Shengding
             and Chen, Yulin and Chan, Chi-Min
             and Chen, Weize and Yi, Jing
             and Zhao, Weilin and Wang, Xiaozhi
             and Liu, Zhiyuan and Zheng, Hai-Tao
             and Chen, Jianfei and Liu, Yang
             and Tang, Jie and Li, Juanzi
             and Sun, Maosong},
    journal = {Nature Machine Intelligence},
    volume = {5},
    number = {3},
    year = {2023},
    month = {Jun},
    pages = {220-235},
}


@misc{liu2023goat,
      title={Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks}, 
      author={Tiedong Liu and Bryan Kian Hsiang Low},
      year={2023},
      eprint={2305.14201},
      archivePrefix={arXiv},
}


@article{Ayling2022,
    Author = {Ayling, Jacqui and Chapman, Adriane},
    Title = {Putting AI ethics to work: are the tools fit for purpose?},
    Journal = {AI and Ethics},
    Volume = {2},
    Number = {3},
    Year = {2022},
    Month = {aug},
    Pages = {405-429},
}
